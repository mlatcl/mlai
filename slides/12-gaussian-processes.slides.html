<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2015-12-15">
  <title>Special Topics: Gaussian Processes</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="reveal.js/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {
         extensions: ["color.js"]
      }
    });
  </script>
  <script src="figure-animate.js"></script>
</head>
<body>
\[\newcommand{\tk}[1]{}
%\newcommand{\tk}[1]{\textbf{TK}: #1}
\newcommand{\Amatrix}{\mathbf{A}}
\newcommand{\KL}[2]{\text{KL}\left( #1\,\|\,#2 \right)}
\newcommand{\Kaast}{\kernelMatrix_{\mathbf{ \ast}\mathbf{ \ast}}}
\newcommand{\Kastu}{\kernelMatrix_{\mathbf{ \ast} \inducingVector}}
\newcommand{\Kff}{\kernelMatrix_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\Kfu}{\kernelMatrix_{\mappingFunctionVector \inducingVector}}
\newcommand{\Kuast}{\kernelMatrix_{\inducingVector \bf\ast}}
\newcommand{\Kuf}{\kernelMatrix_{\inducingVector \mappingFunctionVector}}
\newcommand{\Kuu}{\kernelMatrix_{\inducingVector \inducingVector}}
\newcommand{\Kuui}{\Kuu^{-1}}
\newcommand{\Qaast}{\mathbf{Q}_{\bf \ast \ast}}
\newcommand{\Qastf}{\mathbf{Q}_{\ast \mappingFunction}}
\newcommand{\Qfast}{\mathbf{Q}_{\mappingFunctionVector \bf \ast}}
\newcommand{\Qff}{\mathbf{Q}_{\mappingFunctionVector \mappingFunctionVector}}
\newcommand{\aMatrix}{\mathbf{A}}
\newcommand{\aScalar}{a}
\newcommand{\aVector}{\mathbf{a}}
\newcommand{\acceleration}{a}
\newcommand{\bMatrix}{\mathbf{B}}
\newcommand{\bScalar}{b}
\newcommand{\bVector}{\mathbf{b}}
\newcommand{\basisFunc}{\phi}
\newcommand{\basisFuncVector}{\boldsymbol{ \basisFunc}}
\newcommand{\basisFunction}{\phi}
\newcommand{\basisLocation}{\mu}
\newcommand{\basisMatrix}{\boldsymbol{ \Phi}}
\newcommand{\basisScalar}{\basisFunction}
\newcommand{\basisVector}{\boldsymbol{ \basisFunction}}
\newcommand{\activationFunction}{\phi}
\newcommand{\activationMatrix}{\boldsymbol{ \Phi}}
\newcommand{\activationScalar}{\basisFunction}
\newcommand{\activationVector}{\boldsymbol{ \basisFunction}}
\newcommand{\bigO}{\mathcal{O}}
\newcommand{\binomProb}{\pi}
\newcommand{\cMatrix}{\mathbf{C}}
\newcommand{\cbasisMatrix}{\hat{\boldsymbol{ \Phi}}}
\newcommand{\cdataMatrix}{\hat{\dataMatrix}}
\newcommand{\cdataScalar}{\hat{\dataScalar}}
\newcommand{\cdataVector}{\hat{\dataVector}}
\newcommand{\centeredKernelMatrix}{\mathbf{ \MakeUppercase{\centeredKernelScalar}}}
\newcommand{\centeredKernelScalar}{b}
\newcommand{\centeredKernelVector}{\centeredKernelScalar}
\newcommand{\centeringMatrix}{\mathbf{H}}
\newcommand{\chiSquaredDist}[2]{\chi_{#1}^{2}\left(#2\right)}
\newcommand{\chiSquaredSamp}[1]{\chi_{#1}^{2}}
\newcommand{\conditionalCovariance}{\boldsymbol{ \Sigma}}
\newcommand{\coregionalizationMatrix}{\mathbf{B}}
\newcommand{\coregionalizationScalar}{b}
\newcommand{\coregionalizationVector}{\mathbf{ \coregionalizationScalar}}
\newcommand{\covDist}[2]{\text{cov}_{#2}\left(#1\right)}
\newcommand{\covSamp}[1]{\text{cov}\left(#1\right)}
\newcommand{\covarianceScalar}{c}
\newcommand{\covarianceVector}{\mathbf{ \covarianceScalar}}
\newcommand{\covarianceMatrix}{\mathbf{C}}
\newcommand{\covarianceMatrixTwo}{\boldsymbol{ \Sigma}}
\newcommand{\croupierScalar}{s}
\newcommand{\croupierVector}{\mathbf{ \croupierScalar}}
\newcommand{\croupierMatrix}{\mathbf{ \MakeUppercase{\croupierScalar}}}
\newcommand{\dataDim}{p}
\newcommand{\dataIndex}{i}
\newcommand{\dataIndexTwo}{j}
\newcommand{\dataMatrix}{\mathbf{Y}}
\newcommand{\dataScalar}{y}
\newcommand{\dataSet}{\mathcal{D}}
\newcommand{\dataStd}{\sigma}
\newcommand{\dataVector}{\mathbf{ \dataScalar}}
\newcommand{\decayRate}{d}
\newcommand{\degreeMatrix}{\mathbf{ \MakeUppercase{\degreeScalar}}}
\newcommand{\degreeScalar}{d}
\newcommand{\degreeVector}{\mathbf{ \degreeScalar}}
% Already defined by latex
%\newcommand{\det}[1]{\left|#1\right|}
\newcommand{\diag}[1]{\text{diag}\left(#1\right)}
\newcommand{\diagonalMatrix}{\mathbf{D}}
\newcommand{\diff}[2]{\frac{\text{d}#1}{\text{d}#2}}
\newcommand{\diffTwo}[2]{\frac{\text{d}^2#1}{\text{d}#2^2}}
\newcommand{\displacement}{x}
\newcommand{\displacementVector}{\textbf{\displacement}}
\newcommand{\distanceMatrix}{\mathbf{ \MakeUppercase{\distanceScalar}}}
\newcommand{\distanceScalar}{d}
\newcommand{\distanceVector}{\mathbf{ \distanceScalar}}
\newcommand{\eigenvaltwo}{\ell}
\newcommand{\eigenvaltwoMatrix}{\mathbf{L}}
\newcommand{\eigenvaltwoVector}{\mathbf{l}}
\newcommand{\eigenvalue}{\lambda}
\newcommand{\eigenvalueMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\eigenvalueVector}{\boldsymbol{ \lambda}}
\newcommand{\eigenvector}{\mathbf{ \eigenvectorScalar}}
\newcommand{\eigenvectorMatrix}{\mathbf{U}}
\newcommand{\eigenvectorScalar}{u}
\newcommand{\eigenvectwo}{\mathbf{v}}
\newcommand{\eigenvectwoMatrix}{\mathbf{V}}
\newcommand{\eigenvectwoScalar}{v}
\newcommand{\entropy}[1]{\mathcal{H}\left(#1\right)}
\newcommand{\errorFunction}{E}
\newcommand{\expDist}[2]{\left<#1\right>_{#2}}
\newcommand{\expSamp}[1]{\left<#1\right>}
\newcommand{\expectation}[1]{\left\langle #1 \right\rangle }
\newcommand{\expectationDist}[2]{\left\langle #1 \right\rangle _{#2}}
\newcommand{\expectedDistanceMatrix}{\mathcal{D}}
\newcommand{\eye}{\mathbf{I}}
\newcommand{\fantasyDim}{r}
\newcommand{\fantasyMatrix}{\mathbf{ \MakeUppercase{\fantasyScalar}}}
\newcommand{\fantasyScalar}{z}
\newcommand{\fantasyVector}{\mathbf{ \fantasyScalar}}
\newcommand{\featureStd}{\varsigma}
\newcommand{\gammaCdf}[3]{\mathcal{GAMMA CDF}\left(#1|#2,#3\right)}
\newcommand{\gammaDist}[3]{\mathcal{G}\left(#1|#2,#3\right)}
\newcommand{\gammaSamp}[2]{\mathcal{G}\left(#1,#2\right)}
\newcommand{\gaussianDist}[3]{\mathcal{N}\left(#1|#2,#3\right)}
\newcommand{\gaussianSamp}[2]{\mathcal{N}\left(#1,#2\right)}
\newcommand{\given}{|}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\heaviside}{H}
\newcommand{\hiddenMatrix}{\mathbf{ \MakeUppercase{\hiddenScalar}}}
\newcommand{\hiddenScalar}{h}
\newcommand{\hiddenVector}{\mathbf{ \hiddenScalar}}
\newcommand{\identityMatrix}{\eye}
\newcommand{\inducingInputScalar}{z}
\newcommand{\inducingInputVector}{\mathbf{ \inducingInputScalar}}
\newcommand{\inducingInputMatrix}{\mathbf{Z}}
\newcommand{\inducingScalar}{u}
\newcommand{\inducingVector}{\mathbf{ \inducingScalar}}
\newcommand{\inducingMatrix}{\mathbf{U}}
\newcommand{\inlineDiff}[2]{\text{d}#1/\text{d}#2}
\newcommand{\inputDim}{q}
\newcommand{\inputMatrix}{\mathbf{X}}
\newcommand{\inputScalar}{x}
\newcommand{\inputSpace}{\mathcal{X}}
\newcommand{\inputVals}{\inputVector}
\newcommand{\inputVector}{\mathbf{ \inputScalar}}
\newcommand{\iterNum}{k}
\newcommand{\kernel}{\kernelScalar}
\newcommand{\kernelMatrix}{\mathbf{K}}
\newcommand{\kernelScalar}{k}
\newcommand{\kernelVector}{\mathbf{ \kernelScalar}}
\newcommand{\kff}{\kernelScalar_{\mappingFunction \mappingFunction}}
\newcommand{\kfu}{\kernelVector_{\mappingFunction \inducingScalar}}
\newcommand{\kuf}{\kernelVector_{\inducingScalar \mappingFunction}}
\newcommand{\kuu}{\kernelVector_{\inducingScalar \inducingScalar}}
\newcommand{\lagrangeMultiplier}{\lambda}
\newcommand{\lagrangeMultiplierMatrix}{\boldsymbol{ \Lambda}}
\newcommand{\lagrangian}{L}
\newcommand{\laplacianFactor}{\mathbf{ \MakeUppercase{\laplacianFactorScalar}}}
\newcommand{\laplacianFactorScalar}{m}
\newcommand{\laplacianFactorVector}{\mathbf{ \laplacianFactorScalar}}
\newcommand{\laplacianMatrix}{\mathbf{L}}
\newcommand{\laplacianScalar}{\ell}
\newcommand{\laplacianVector}{\mathbf{ \ell}}
\newcommand{\latentDim}{q}
\newcommand{\latentDistanceMatrix}{\boldsymbol{ \Delta}}
\newcommand{\latentDistanceScalar}{\delta}
\newcommand{\latentDistanceVector}{\boldsymbol{ \delta}}
\newcommand{\latentForce}{f}
\newcommand{\latentFunction}{u}
\newcommand{\latentFunctionVector}{\mathbf{ \latentFunction}}
\newcommand{\latentFunctionMatrix}{\mathbf{ \MakeUppercase{\latentFunction}}}
\newcommand{\latentIndex}{j}
\newcommand{\latentScalar}{z}
\newcommand{\latentVector}{\mathbf{ \latentScalar}}
\newcommand{\latentMatrix}{\mathbf{Z}}
\newcommand{\learnRate}{\eta}
\newcommand{\lengthScale}{\ell}
\newcommand{\rbfWidth}{\ell}
\newcommand{\likelihoodBound}{\mathcal{L}}
\newcommand{\likelihoodFunction}{L}
\newcommand{\locationScalar}{\mu}
\newcommand{\locationVector}{\boldsymbol{ \locationScalar}}
\newcommand{\locationMatrix}{\mathbf{M}}
\newcommand{\variance}[1]{\text{var}\left( #1 \right)}
\newcommand{\mappingFunction}{f}
\newcommand{\mappingFunctionMatrix}{\mathbf{F}}
\newcommand{\mappingFunctionTwo}{g}
\newcommand{\mappingFunctionTwoMatrix}{\mathbf{G}}
\newcommand{\mappingFunctionTwoVector}{\mathbf{ \mappingFunctionTwo}}
\newcommand{\mappingFunctionVector}{\mathbf{ \mappingFunction}}
\newcommand{\scaleScalar}{s}
\newcommand{\mappingScalar}{w}
\newcommand{\mappingVector}{\mathbf{ \mappingScalar}}
\newcommand{\mappingMatrix}{\mathbf{W}}
\newcommand{\mappingScalarTwo}{v}
\newcommand{\mappingVectorTwo}{\mathbf{ \mappingScalarTwo}}
\newcommand{\mappingMatrixTwo}{\mathbf{V}}
\newcommand{\maxIters}{K}
\newcommand{\meanMatrix}{\mathbf{M}}
\newcommand{\meanScalar}{\mu}
\newcommand{\meanTwoMatrix}{\mathbf{M}}
\newcommand{\meanTwoScalar}{m}
\newcommand{\meanTwoVector}{\mathbf{ \meanTwoScalar}}
\newcommand{\meanVector}{\boldsymbol{ \meanScalar}}
\newcommand{\mrnaConcentration}{m}
\newcommand{\naturalFrequency}{\omega}
\newcommand{\neighborhood}[1]{\mathcal{N}\left( #1 \right)}
\newcommand{\neilurl}{http://inverseprobability.com/}
\newcommand{\noiseMatrix}{\boldsymbol{ E}}
\newcommand{\noiseScalar}{\epsilon}
\newcommand{\noiseVector}{\boldsymbol{ \epsilon}}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\normalizedLaplacianMatrix}{\hat{\mathbf{L}}}
\newcommand{\normalizedLaplacianScalar}{\hat{\ell}}
\newcommand{\normalizedLaplacianVector}{\hat{\mathbf{ \ell}}}
\newcommand{\numActive}{m}
\newcommand{\numBasisFunc}{m}
\newcommand{\numComponents}{m}
\newcommand{\numComps}{K}
\newcommand{\numData}{n}
\newcommand{\numFeatures}{K}
\newcommand{\numHidden}{h}
\newcommand{\numInducing}{m}
\newcommand{\numLayers}{\ell}
\newcommand{\numNeighbors}{K}
\newcommand{\numSequences}{s}
\newcommand{\numSuccess}{s}
\newcommand{\numTasks}{m}
\newcommand{\numTime}{T}
\newcommand{\numTrials}{S}
\newcommand{\outputIndex}{j}
\newcommand{\paramVector}{\boldsymbol{ \theta}}
\newcommand{\parameterMatrix}{\boldsymbol{ \Theta}}
\newcommand{\parameterScalar}{\theta}
\newcommand{\parameterVector}{\boldsymbol{ \parameterScalar}}
\newcommand{\partDiff}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\precisionScalar}{j}
\newcommand{\precisionVector}{\mathbf{ \precisionScalar}}
\newcommand{\precisionMatrix}{\mathbf{J}}
\newcommand{\pseudotargetScalar}{\widetilde{y}}
\newcommand{\pseudotargetVector}{\mathbf{ \pseudotargetScalar}}
\newcommand{\pseudotargetMatrix}{\mathbf{ \widetilde{Y}}}
\newcommand{\rank}[1]{\text{rank}\left(#1\right)}
\newcommand{\rayleighDist}[2]{\mathcal{R}\left(#1|#2\right)}
\newcommand{\rayleighSamp}[1]{\mathcal{R}\left(#1\right)}
\newcommand{\responsibility}{r}
\newcommand{\rotationScalar}{r}
\newcommand{\rotationVector}{\mathbf{ \rotationScalar}}
\newcommand{\rotationMatrix}{\mathbf{R}}
\newcommand{\sampleCovScalar}{s}
\newcommand{\sampleCovVector}{\mathbf{ \sampleCovScalar}}
\newcommand{\sampleCovMatrix}{\mathbf{s}}
\newcommand{\scalarProduct}[2]{\left\langle{#1},{#2}\right\rangle}
\newcommand{\sign}[1]{\text{sign}\left(#1\right)}
\newcommand{\sigmoid}[1]{\sigma\left(#1\right)}
\newcommand{\singularvalue}{\ell}
\newcommand{\singularvalueMatrix}{\mathbf{L}}
\newcommand{\singularvalueVector}{\mathbf{l}}
\newcommand{\sorth}{\mathbf{u}}
\newcommand{\spar}{\lambda}
\newcommand{\trace}[1]{\text{tr}\left(#1\right)}
\newcommand{\BasalRate}{B}
\newcommand{\DampingCoefficient}{C}
\newcommand{\DecayRate}{D}
\newcommand{\Displacement}{X}
\newcommand{\LatentForce}{F}
\newcommand{\Mass}{M}
\newcommand{\Sensitivity}{S}
\newcommand{\basalRate}{b}
\newcommand{\dampingCoefficient}{c}
\newcommand{\mass}{m}
\newcommand{\sensitivity}{s}
\newcommand{\springScalar}{\kappa}
\newcommand{\springVector}{\boldsymbol{ \kappa}}
\newcommand{\springMatrix}{\boldsymbol{ \mathcal{K}}}
\newcommand{\tfConcentration}{p}
\newcommand{\tfDecayRate}{\delta}
\newcommand{\tfMrnaConcentration}{f}
\newcommand{\tfVector}{\mathbf{ \tfConcentration}}
\newcommand{\velocity}{v}
\newcommand{\sufficientStatsScalar}{g}
\newcommand{\sufficientStatsVector}{\mathbf{ \sufficientStatsScalar}}
\newcommand{\sufficientStatsMatrix}{\mathbf{G}}
\newcommand{\switchScalar}{s}
\newcommand{\switchVector}{\mathbf{ \switchScalar}}
\newcommand{\switchMatrix}{\mathbf{S}}
\newcommand{\tr}[1]{\text{tr}\left(#1\right)}
\newcommand{\loneNorm}[1]{\left\Vert #1 \right\Vert_1}
\newcommand{\ltwoNorm}[1]{\left\Vert #1 \right\Vert_2}
\newcommand{\onenorm}[1]{\left\vert#1\right\vert_1}
\newcommand{\twonorm}[1]{\left\Vert #1 \right\Vert}
\newcommand{\vScalar}{v}
\newcommand{\vVector}{\mathbf{v}}
\newcommand{\vMatrix}{\mathbf{V}}
\newcommand{\varianceDist}[2]{\text{var}_{#2}\left( #1 \right)}
% Already defined by latex
%\newcommand{\vec}{#1:}
\newcommand{\vecb}[1]{\left(#1\right):}
\newcommand{\weightScalar}{w}
\newcommand{\weightVector}{\mathbf{ \weightScalar}}
\newcommand{\weightMatrix}{\mathbf{W}}
\newcommand{\weightedAdjacencyMatrix}{\mathbf{A}}
\newcommand{\weightedAdjacencyScalar}{a}
\newcommand{\weightedAdjacencyVector}{\mathbf{ \weightedAdjacencyScalar}}
\newcommand{\onesVector}{\mathbf{1}}
\newcommand{\zerosVector}{\mathbf{0}}
\]
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Special Topics: Gaussian Processes</h1>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2015-12-15</time></p>
  <p class="venue" style="text-align:center">University of Sheffield</p>
</section>

<section class="slide level2">

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
</section>
<section id="review" class="slide level2">
<h2>Review</h2>
<ul>
<li>Last week: Logistic Regression and Generalised Linear Models</li>
<li>Introduced link functions and different transformations.</li>
<li>Showed examples in classification and mentioned possibilities for disease rate models.</li>
<li>This week:
<ul>
<li>Gaussian Processes: non parametric Bayesian modelling }</li>
</ul></li>
</ul>
</section>
<section id="generalized-linear-models" class="slide level2">
<h2>Generalized Linear Models</h2>
<p>Logistic regression is part of a wider class of models known as <em>generalized linear models</em>. In these models we determine that some characteristic of the model is speicified by a function that is liniear in the parameters. So we might suggest that <span class="math display">\[
\log \frac{p(\inputVector)}{1-p(\inputVector)} = \mappingFunction(\inputVector; \mappingVector)
\]</span> where <span class="math inline">\(\mappingFunction(\inputVector; \mappingVector)\)</span> is a linear-in-the-parameters function (here the parameters are <span class="math inline">\(\mappingVector\)</span>, which is generally non-linear in the inputs. So far we have considered basis function models of the form <span class="math display">\[
\mappingFunction(\inputVector) =
\mappingVector^\top \basisVector(\inputVector).
\]</span> </p>
</section>
<section id="gaussian-processes" class="slide level2">
<h2>Gaussian Processes</h2>

</section>
<section id="gaussian-processes-1" class="slide level2">
<h2>Gaussian Processes</h2>
<ul>
<li>Basis function models give non-linear predictions.</li>
<li>Need to choose number and location of basis functions.</li>
<li>Gaussian processes is a general framework (basis functions special case)</li>
<li>Within the framework you can consider models with infinite basis functions.</li>
</ul>
<p>import numpy as np np.random.seed(4949)</p>
<p>import teaching_plots as plot import pods</p>
</section>
<section id="prediction-of-mappingfunction_2-from-mappingfunction_1" class="slide level2">
<h2>Prediction of <span class="math inline">\(\mappingFunction_{2}\)</span> from <span class="math inline">\(\mappingFunction_{1}\)</span></h2>
<script>
showDivs(9, 'two_point_sample2');
</script>
<p><small></small> <input id="range-two_point_sample2" type="range" min="9" max="12" value="9" onchange="setDivs('two_point_sample2')" oninput="setDivs('two_point_sample2')"> <button onclick="plusDivs(-1, 'two_point_sample2')">❮</button> <button onclick="plusDivs(1, 'two_point_sample2')">❯</button></p>
</section>
<section id="section" class="slide level2">
<h2></h2>
<div class="two_point_sample2" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample009.svg" width style=" ">
</object>
</div>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<div class="two_point_sample2" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample010.svg" width style=" ">
</object>
</div>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<div class="two_point_sample2" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample011.svg" width style=" ">
</object>
</div>
</section>
<section id="section-3" class="slide level2">
<h2></h2>
<div class="two_point_sample2" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample012.svg" width style=" ">
</object>
</div>
</section>
<section id="prediction-of-mappingfunction_2-from-mappingfunction_1-1" class="slide level2">
<h2>Prediction of <span class="math inline">\(\mappingFunction_{2}\)</span> from <span class="math inline">\(\mappingFunction_{1}\)</span></h2>
<p><small> * The single contour of the Gaussian density represents the <font color="cyan">joint distribution, <span class="math inline">\(p(\mappingFunction_1, \mappingFunction_2)\)</span></font></p>
<div class="fragment">
<ul>
<li>We observe that <font color="magenta"><span class="math inline">\(\mappingFunction_1=?\)</span></font></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Conditional density: <font color="cyan"><span class="math inline">\(p(\mappingFunction_2|\mappingFunction_1=?)\)</span></font> </small></li>
</ul>
</div>
</section>
<section id="prediction-with-correlated-gaussians" class="slide level2">
<h2>Prediction with Correlated Gaussians</h2>
<ul>
<li><p>Prediction of <span class="math inline">\(\mappingFunction_2\)</span> from <span class="math inline">\(\mappingFunction_1\)</span> requires <em>conditional density</em>.</p></li>
<li><p>Conditional density is <em>also</em> Gaussian. <span class="math display">\[
p(\mappingFunction_2|\mappingFunction_1) = {\mathcal{N}\left(\mappingFunction_2|\frac{\kernelScalar_{1, 2}}{\kernelScalar_{1, 1}}\mappingFunction_1,\kernelScalar_{2, 2} - \frac{\kernelScalar_{1,2}^2}{\kernelScalar_{1,1}}\right)}
\]</span> where covariance of joint density is given by <span class="math display">\[
\kernelMatrix= \begin{bmatrix} \kernelScalar_{1, 1} &amp; \kernelScalar_{1, 2}\\ \kernelScalar_{2, 1} &amp; \kernelScalar_{2, 2}\end{bmatrix}
\]</span></p></li>
</ul>
</section>
<section id="prediction-of-mappingfunction_8-from-mappingfunction_1" class="slide level2">
<h2>Prediction of <span class="math inline">\(\mappingFunction_{8}\)</span> from <span class="math inline">\(\mappingFunction_{1}\)</span></h2>
<script>
showDivs(13, 'two_point_sample3');
</script>
<p><small></small> <input id="range-two_point_sample3" type="range" min="13" max="17" value="13" onchange="setDivs('two_point_sample3')" oninput="setDivs('two_point_sample3')"> <button onclick="plusDivs(-1, 'two_point_sample3')">❮</button> <button onclick="plusDivs(1, 'two_point_sample3')">❯</button></p>
</section>
<section id="section-4" class="slide level2">
<h2></h2>
<div class="two_point_sample3" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample013.svg" width style=" ">
</object>
</div>
</section>
<section id="section-5" class="slide level2">
<h2></h2>
<div class="two_point_sample3" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample014.svg" width style=" ">
</object>
</div>
</section>
<section id="section-6" class="slide level2">
<h2></h2>
<div class="two_point_sample3" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample015.svg" width style=" ">
</object>
</div>
</section>
<section id="section-7" class="slide level2">
<h2></h2>
<div class="two_point_sample3" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample016.svg" width style=" ">
</object>
</div>
</section>
<section id="section-8" class="slide level2">
<h2></h2>
<div class="two_point_sample3" style="text-align:center;">
<object class="svgplot " data="../slides/diagrams/gp/two_point_sample017.svg" width style=" ">
</object>
</div>
</section>
<section id="details" class="slide level2">
<h2>Details</h2>
<ul>
<li>The single contour of the Gaussian density represents the <font color="yellow">joint distribution, <span class="math inline">\(p(\mappingFunction_1, \mappingFunction_8)\)</span></font></li>
</ul>
<div class="fragment">
<ul>
<li>We observe a value for <font color="magenta"><span class="math inline">\(\mappingFunction_1=-?\)</span></font></li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Conditional density: <font color="cyan"><span class="math inline">\(p(\mappingFunction_5|\mappingFunction_1=?)\)</span></font>.</li>
</ul>
</div>
</section>
<section id="prediction-with-correlated-gaussians-1" class="slide level2">
<h2>Prediction with Correlated Gaussians</h2>
<ul>
<li><p>Prediction of <span class="math inline">\(\mappingFunctionVector_*\)</span> from <span class="math inline">\(\mappingFunctionVector\)</span> requires multivariate <em>conditional density</em>.</p></li>
<li><p>Multivariate conditional density is <em>also</em> Gaussian. <large> <span class="math display">\[
p(\mappingFunctionVector_*|\mappingFunctionVector) = {\mathcal{N}\left(\mappingFunctionVector_*|\kernelMatrix_{*,\mappingFunctionVector}\kernelMatrix_{\mappingFunctionVector,\mappingFunctionVector}^{-1}\mappingFunctionVector,\kernelMatrix_{*,*}-\kernelMatrix_{*,\mappingFunctionVector} \kernelMatrix_{\mappingFunctionVector,\mappingFunctionVector}^{-1}\kernelMatrix_{\mappingFunctionVector,*}\right)}
\]</span> </large></p></li>
<li><p>Here covariance of joint density is given by <span class="math display">\[
\kernelMatrix= \begin{bmatrix} \kernelMatrix_{\mappingFunctionVector, \mappingFunctionVector} &amp; \kernelMatrix_{*, \mappingFunctionVector}\\ \kernelMatrix_{\mappingFunctionVector, *} &amp; \kernelMatrix_{*, *}\end{bmatrix}
\]</span></p></li>
</ul>
</section>
<section id="prediction-with-correlated-gaussians-2" class="slide level2">
<h2>Prediction with Correlated Gaussians</h2>
<ul>
<li><p>Prediction of <span class="math inline">\(\mappingFunctionVector_*\)</span> from <span class="math inline">\(\mappingFunctionVector\)</span> requires multivariate <em>conditional density</em>.</p></li>
<li><p>Multivariate conditional density is <em>also</em> Gaussian. <large> <span class="math display">\[
p(\mappingFunctionVector_*|\mappingFunctionVector) = {\mathcal{N}\left(\mappingFunctionVector_*|{\boldsymbol{{\mu}}},\boldsymbol{\Sigma}\right)}
\]</span> <span class="math display">\[
{\boldsymbol{{\mu}}}= \kernelMatrix_{*,\mappingFunctionVector}\kernelMatrix_{\mappingFunctionVector,\mappingFunctionVector}^{-1}\mappingFunctionVector
\]</span> <span class="math display">\[\boldsymbol{\Sigma} = \kernelMatrix_{*,*}-\kernelMatrix_{*,\mappingFunctionVector} \kernelMatrix_{\mappingFunctionVector,\mappingFunctionVector}^{-1}\kernelMatrix_{\mappingFunctionVector,*}
\]</span> </large></p></li>
<li><p>Here covariance of joint density is given by <span class="math display">\[
\kernelMatrix= \begin{bmatrix} \kernelMatrix_{\mappingFunctionVector, \mappingFunctionVector} &amp; \kernelMatrix_{*, \mappingFunctionVector}\\ \kernelMatrix_{\mappingFunctionVector, *} &amp; \kernelMatrix_{*, *}\end{bmatrix}
\]</span></p></li>
</ul>
</section>
<section id="marginal-likelihood" class="slide level2">
<h2>Marginal Likelihood</h2>

</section>
<section id="sampling-from-the-prior" class="slide level2">
<h2>Sampling from the Prior</h2>

</section>
<section>
<section id="set-prior-variance-on-w" class="title-slide slide level1">
<h1>set prior variance on w</h1>
<p>alpha = 4. # set the order of the polynomial basis set degree = 5 # set the noise variance sigma2 = 0.01</p>
<p>import numpy as np</p>
<p>def polynomial(x, degree, loc, scale): degrees = np.arange(degree+1) return ((x-loc)/scale)**degrees</p>
<p>import pods</p>
<p>data = pods.datasets.olympic_marathon_men() x = data[‘X’] y = data[‘Y’]</p>
<p>loc = 1950. scale = 100. num_data = x.shape[0] num_pred_data = 100 # how many points to use for plotting predictions x_pred = np.linspace(1880, 2030, num_pred_data)[:, None] # input locations for predictions Phi_pred = polynomial(x_pred, degree=degree, loc=loc, scale=scale) Phi = polynomial(x, degree=degree, loc=loc, scale=scale)</p>
</section>
<section id="weight-space-view" class="slide level2">
<h2>Weight Space View</h2>
<p><span class="math display">\[
\weightVector \sim \gaussianSamp{\zerosVector}{\alpha\eye},
\]</span>  <span class="math display">\[
\mappingFunction(\inputVector) =
\weightVector^\top \basisVector(\inputVector).
\]</span> </p>
</section>
<section id="function-space-view" class="slide level2">
<h2>Function Space View</h2>
<p><span class="math display">\[
\weightVector \sim \gaussianSamp{\zerosVector}{\alpha \eye}
\]</span>  <span class="math display">\[
\basisMatrix = \begin{bmatrix}\basisVector(\inputVector_1) \\ \vdots \\
\basisVector(\inputVector_n)\end{bmatrix}
\]</span>  <span class="math display">\[
\mappingFunctionVector = \begin{bmatrix} \mappingFunction_1
\\ \vdots \mappingFunction_n\end{bmatrix}
\]</span> in the form <span class="math display">\[
\mappingFunctionVector = \basisMatrix
\weightVector.
\]</span>}</p>
<p><span class="math display">\[
\mappingFunctionVector \sim \gaussianSamp{\zerosVector}{\alpha \basisMatrix\basisMatrix^\top}.
\]</span></p>
<p><span class="math display">\[
\kernelMatrix = \alpha
\basisMatrix\basisMatrix^\top.
\]</span></p>
<p>K = alpha*np.dot(Phi_pred, Phi_pred.T)</p>
<p>for i in np.arange(10): f_sample = np.random.multivariate_normal(mean=np.zeros(x_pred.size), cov=K) plt.plot(x_pred.flatten(), f_sample.flatten())</p>
<p>fig, ax = plt.subplots(figsize=(8,8)) im = ax.imshow(K, interpolation=‘none’) fig.colorbar(im)</p>
</section>
<section id="probability-winning-olympics" class="slide level2">
<h2>Probability Winning Olympics?</h2>
<ul>
<li>He was a formidable Marathon runner.</li>
<li>In 1946 he ran a time 2 hours 46 minutes.
<ul>
<li>That’s a pace of 3.95 min/km.</li>
</ul></li>
<li>What is the probability he would have won an Olympics if one had been held in 1946?</li>
</ul>
<p>import GPy</p>
<p>m_full = GPy.models.GPRegression(x,yhat) _ = m_full.optimize() # Optimize parameters of covariance function</p>
<p>xt = np.linspace(1870,2030,200)[:,np.newaxis] yt_mean, yt_var = m_full.predict(xt) yt_sd=np.sqrt(yt_var)</p>
</section>
<section id="olympic-marathon-data-gp" class="slide level2">
<h2>Olympic Marathon Data GP</h2>
<div class="figure">
<div id="olympic-marathon-gp-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/gp/olympic-marathon-gp.svg" width style=" ">
</object>
</div>
</div>
</section>
<section id="della-gatta-gene-data" class="slide level2">
<h2>Della Gatta Gene Data</h2>
<ul>
<li>Given given expression levels in the form of a time series from <span class="citation" data-cites="DellaGatta:direct08">Della Gatta et al. (2008)</span>.</li>
</ul>
<p>import numpy as np import pods</p>
<p>data = pods.datasets.della_gatta_TRP63_gene_expression(data_set=‘della_gatta’,gene_number=937)</p>
<p>x = data[‘X’] y = data[‘Y’]</p>
<p>offset = y.mean() scale = np.sqrt(y.var())</p>
</section>
<section id="della-gatta-gene-data-1" class="slide level2">
<h2>Della Gatta Gene Data</h2>
<div class="figure">
<div id="della-gatta-gene-data-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/datasets/della-gatta-gene.svg" width="80%" style=" ">
</object>
</div>
</div>
</section>
<section id="gene-expression-example" class="slide level2">
<h2>Gene Expression Example</h2>
<ul>
<li>Want to detect if a gene is expressed or not, fit a GP to each gene <span class="citation" data-cites="Kalaitzis:simple11">Kalaitzis and Lawrence (2011)</span>.</li>
</ul>
</section>
<section id="section-9" class="slide level2">
<h2></h2>
<div class="figure">
<div id="a-simple-approach-to-ranking-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/health/1471-2105-12-180_1.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<center>
<a href="http://www.biomedcentral.com/1471-2105/12/180" class="uri">http://www.biomedcentral.com/1471-2105/12/180</a>
</center>
</section>
<section id="section-10" class="slide level2">
<h2></h2>
<p>import GPy</p>
<p>m_full = GPy.models.GPRegression(x,yhat) m_full.kern.lengthscale=50 _ = m_full.optimize() # Optimize parameters of covariance function</p>
<p>xt = np.linspace(-20,260,200)[:,np.newaxis] yt_mean, yt_var = m_full.predict(xt) yt_sd=np.sqrt(yt_var)</p>
</section>
<section id="tp53-gene-data-gp" class="slide level2">
<h2>TP53 Gene Data GP</h2>
<div class="figure">
<div id="della-gatta-gene-gp-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/gp/della-gatta-gene-gp.svg" width="80%" style=" ">
</object>
</div>
</div>
<p>m_full2 = GPy.models.GPRegression(x,yhat) m_full2.kern.lengthscale=2000 _ = m_full2.optimize() # Optimize parameters of covariance function</p>
</section>
<section id="tp53-gene-data-gp-1" class="slide level2">
<h2>TP53 Gene Data GP</h2>
<div class="figure">
<div id="della-gatta-gene-gp2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/gp/della-gatta-gene-gp2.svg" width="80%" style=" ">
</object>
</div>
</div>
<p>m_full3 = GPy.models.GPRegression(x,yhat) m_full3.kern.lengthscale=20 m_full3.likelihood.variance=0.001 _ = m_full3.optimize() # Optimize parameters of covariance function</p>
</section>
<section id="tp53-gene-data-gp-2" class="slide level2">
<h2>TP53 Gene Data GP</h2>
<div class="figure">
<div id="della-gatta-gene-gp3-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/gp/della-gatta-gene-gp3.svg" width="80%" style=" ">
</object>
</div>
</div>
</section>
<section id="multiple-optima" class="slide level2">
<h2>Multiple Optima</h2>
<div class="figure">
<div id="gp-multiple-optima000-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/gp/multiple-optima000.svg" width="50%" style=" ">
</object>
</div>
</div>
<!--
## Multiple Optima  {}



<object class="svgplot " data="../slides/diagrams/gp/multiple-optima001.svg" width="" style=" "></object>-->
</section>
<section id="example-prediction-of-malaria-incidence-in-uganda" class="slide level2">
<h2>Example: Prediction of Malaria Incidence in Uganda</h2>
<p><span style="text-align:right"><img class="" src="../slides/diagrams/people/2013_03_28_180606.JPG" width="1.5cm" style="background:none; border:none; box-shadow:none; position:absolute; clip:rect(2662px,1780px,1110px,600px);vertical-align:middle"></span></p>
<ul>
<li>Work with Ricardo Andrade Pacheco, John Quinn and Martin Mubaganzi (Makerere University, Uganda)</li>
<li>See <a href="http://air.ug/research.html">AI-DEV Group</a>.</li>
</ul>
</section>
<section id="malaria-prediction-in-uganda" class="slide level2">
<h2>Malaria Prediction in Uganda</h2>
<div class="figure">
<div id="uganda-districts-2006-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/health/uganda-districts-2006.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<p><span style="text-align:right"><span class="citation" data-cites="Andrade:consistent14 Mubangizi:malaria14">(Andrade-Pacheco et al., 2014; Mubangizi et al., 2014)</span></span></p>
</section>
<section id="kapchorwa-district" class="slide level2">
<h2>Kapchorwa District</h2>
<div class="figure">
<div id="kapchorwa-district-in-uganda-figure" class="figure-frame">
<object class data="../slides/diagrams/health/Kapchorwa_District_in_Uganda.svg" width="50%" style=" ">
</object>
</div>
</div>
</section>
<section id="tororo-district" class="slide level2">
<h2>Tororo District</h2>
<div class="figure">
<div id="tororo-district-in-uganda-figure" class="figure-frame">
<object class data="../slides/diagrams/health/Tororo_District_in_Uganda.svg" width="50%" style=" ">
</object>
</div>
</div>
</section>
<section id="malaria-prediction-in-nagongera-sentinel-site" class="slide level2">
<h2>Malaria Prediction in Nagongera (Sentinel Site)</h2>
<div class="figure">
<div id="sentinel-nagongera-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/health/sentinel_nagongera.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="mubende-district" class="slide level2">
<h2>Mubende District</h2>
<div class="figure">
<div id="mubende-district-in-uganda-figure" class="figure-frame">
<object class data="../slides/diagrams/health/Mubende_District_in_Uganda.svg" width="50%" style=" ">
</object>
</div>
</div>
</section>
<section id="malaria-prediction-in-uganda-1" class="slide level2">
<h2>Malaria Prediction in Uganda</h2>
<div class="figure">
<div id="malaria-prediction-mubende-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/health/mubende.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="gp-school-at-makerere" class="slide level2">
<h2>GP School at Makerere</h2>
<div class="figure">
<div id="-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/gpss/1157497_513423392066576_1845599035_n.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="kabarole-district" class="slide level2">
<h2>Kabarole District</h2>
<div class="figure">
<div id="kabarole-district-in-uganda-figure" class="figure-frame">
<object class data="../slides/diagrams/health/Kabarole_District_in_Uganda.svg" width="50%" style=" ">
</object>
</div>
</div>
</section>
<section id="early-warning-system" class="slide level2">
<h2>Early Warning System</h2>
<div class="figure">
<div id="kabarole-disease-over-time-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/health/kabarole.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="early-warning-systems" class="slide level2">
<h2>Early Warning Systems</h2>
<div class="figure">
<div id="early-warning-system-map-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/health/monitor.gif" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="additive-covariance" class="slide level2">
<h2>Additive Covariance</h2>
<center>
<span class="math display">\[\kernelScalar_f(\inputVector, \inputVector^\prime) = \kernelScalar_g(\inputVector, \inputVector^\prime) + \kernelScalar_h(\inputVector, \inputVector^\prime)\]</span>
</center>
<div class="figure">
<div id="add-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/add_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/add_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
</section>
<section id="section-11" class="slide level2">
<h2></h2>
<div class="figure">
<div id="bialik-friday-the-13th-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/bialik-fridaythe13th-1.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
</section>
<section id="gelman-book" class="slide level2">
<h2>Gelman Book</h2>
<div class="figure">
<div id="bayesian-data-analysis-figure" class="figure-frame">
<table>
<tr>
<td width="50%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/bda_cover_1.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="50%">
<div class="centered" style="">
<img class="" src="../slides/diagrams/ml/bda_cover.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
<p><span style="text-align:right"><span class="citation" data-cites="Gelman:bayesian13">Gelman et al. (2013)</span></span></p>
</section>
<section id="basis-function-covariance" class="slide level2">
<h2>Basis Function Covariance</h2>
<p>%load -s basis_cov mlai.py</p>
<p>%load -s radial mlai.py</p>
<center>
<span class="math display">\[\kernel(\inputVector, \inputVector^\prime) = \basisVector(\inputVector)^\top \basisVector(\inputVector^\prime)\]</span>
</center>
<div class="figure">
<div id="basis-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/basis_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/basis_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
</section>
<section id="brownian-covariance" class="slide level2">
<h2>Brownian Covariance</h2>
<p>%load -s brownian_cov mlai.py</p>
<center>
<span class="math display">\[\kernelScalar(t, t^\prime)=\alpha \min(t, t^\prime)\]</span>
</center>
<div class="figure">
<div id="brownian-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/brownian_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/brownian_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
</section>
<section id="mlp-covariance" class="slide level2">
<h2>MLP Covariance</h2>
<p>%load -s mlp_cov mlai.py</p>
<center>
<span class="math display">\[\kernelScalar(\inputVector, \inputVector^\prime) = \alpha \arcsin\left(\frac{w \inputVector^\top \inputVector^\prime + b}{\sqrt{\left(w \inputVector^\top \inputVector + b + 1\right)\left(w \left.\inputVector^\prime\right.^\top \inputVector^\prime + b + 1\right)}}\right)\]</span>
</center>
<div class="figure">
<div id="mlp-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/mlp_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/mlp_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
</section>
<section id="gpss-gaussian-process-summer-school" class="slide level2">
<h2>GPSS: Gaussian Process Summer School</h2>
<table>
<tr>
<td width="60%">
<ul>
<li><a href="http://gpss.cc" class="uri">http://gpss.cc</a></li>
<li>Next one is in Sheffield in <em>September 2019</em>.</li>
<li>Many lectures from past meetings available online</li>
</ul>
</td>
<td width="40%">
<div style="width:1.5cm;text-align:center">

</div>
</td>
</tr>
</table>
</section>
<section id="gpy-a-gaussian-process-framework-in-python" class="slide level2">
<h2>GPy: A Gaussian Process Framework in Python</h2>
<div class="figure">
<div id="gpy-software-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/gp/gpy.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<center>
<a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a>
</center>
</section>
<section id="gpy-a-gaussian-process-framework-in-python-1" class="slide level2">
<h2>GPy: A Gaussian Process Framework in Python</h2>
<ul>
<li>BSD Licensed software base.</li>
<li>Wide availability of libraries, ‘modern’ scripting language.</li>
<li>Allows us to set projects to undergraduates in Comp Sci that use GPs.</li>
<li>Available through GitHub <a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a></li>
<li>Reproducible Research with Jupyter Notebook.</li>
</ul>
</section>
<section id="features" class="slide level2">
<h2>Features</h2>
<ul>
<li>Probabilistic-style programming (specify the model, not the algorithm).</li>
<li>Non-Gaussian likelihoods.</li>
<li>Multivariate outputs.</li>
<li>Dimensionality reduction.</li>
<li>Approximations for large data sets.</li>
</ul>
</section>
<section id="thanks" class="slide level2 scrollable">
<h2 class="scrollable">Thanks!</h2>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
</section>
<section id="references" class="slide level2 unnumbered scrollable">
<h2 class="unnumbered scrollable">References</h2>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-Andrade:consistent14">
<p>Andrade-Pacheco, R., Mubangizi, M., Quinn, J., Lawrence, N.D., 2014. Consistent mapping of government malaria records across a changing territory delimitation. Malaria Journal 13. <a href="https://doi.org/10.1186/1475-2875-13-S1-P5">https://doi.org/10.1186/1475-2875-13-S1-P5</a></p>
</div>
<div id="ref-DellaGatta:direct08">
<p>Della Gatta, G., Bansal, M., Ambesi-Impiombato, A., Antonini, D., Missero, C., Bernardo, D. di, 2008. Direct targets of the trp63 transcription factor revealed by a combination of gene expression profiling and reverse engineering. Genome Research 18, 939–948. <a href="https://doi.org/10.1101/gr.073601.107">https://doi.org/10.1101/gr.073601.107</a></p>
</div>
<div id="ref-Gelman:bayesian13">
<p>Gelman, A., Carlin, J.B., Stern, H.S., Rubin, D.B., 2013. Bayesian data analysis, 3rd ed. Chapman; Hall.</p>
</div>
<div id="ref-Kalaitzis:simple11">
<p>Kalaitzis, A.A., Lawrence, N.D., 2011. A simple approach to ranking differentially expressed gene expression time courses through Gaussian process regression. BMC Bioinformatics 12. <a href="https://doi.org/10.1186/1471-2105-12-180">https://doi.org/10.1186/1471-2105-12-180</a></p>
</div>
<div id="ref-Mubangizi:malaria14">
<p>Mubangizi, M., Andrade-Pacheco, R., Smith, M.T., Quinn, J., Lawrence, N.D., 2014. Malaria surveillance with multiple data sources using Gaussian process models, in: 1st International Conference on the Use of Mobile ICT in Africa.</p>
</div>
</div>
</section></section>
    </div>
  </div>

  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
          { src: 'reveal.js/plugin/math/math.js', async: true },
          { src: 'reveal.js/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
