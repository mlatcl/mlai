---
layout: lectures
title: Basis Functions
abstract: |
  In the last session we explored least squares for univariate and multivariate *regression*. We introduced *matrices*, *linear algebra* and *derivatives*. 
  
  In this session we will introduce *basis functions* which allow us to implement *non-linear regression models*.
date: 2015-10-20
ipynb: 2015-10-20-week4.ipynb
reveal: 2015-10-20-week4.slides.html
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: Amazon Cambridge and University of Sheffield
  twitter: lawrennd
  url: http://inverseprobability.com
venue: University of Sheffield
transition: None
---

\include{talk-macros.tex}

\displaycode{%matplotlib inline}

\subsection{Nonlinear Regression}

\notes{We've now seen how we may perform linear regression. Now, we
are going to consider how we can perform *non-linear*
regression. However, before we get into the details of how to do that
we first need to consider in what ways the regression can be
non-linear. Multivariate linear regression allows us to build models
that take many features into account when making our prediction. In
this session we are going to introduce *basis functions*. The term
seems complicted, but they are actually based on rather a simple
idea. If we are doing a multivariate linear regression, we get extra
features that *might* help us predict our required response varible
(or target value), $y$. But what if we only have one input value? We
can actually artificially generate more input values with basis
functions.}

\slides{* Problem with Linear Regressionâ€”$\inputVector$ may not be linearly related to $\dataVector$.
* Potential solution: create a feature space: define $\basisFunc(\inputVector)$ where $\basisFunc(\cdot)$ is a nonlinear function of $\inputVector$.
* Model for target is a linear combination of these nonlinear functions 
  $$\mappingFunction(\inputVector) = \sum_{j=1}^\numBasisFunc \mappingScalar_j \basisFunc_j(\inputVector)$$}

\subsection{Non-linear in the Inputs}

\notes{When we refer to non-linear regression, we are normally
referring to whether the regression is non-linear in the input space,
or non-linear in the *covariates*. The covariates are the observations
that move with the target (or *response*) variable. In our notation we
have been using $\inputVector_i$ to represent a vector of the
covariates associated with the $i$th observation. The coresponding
response variable is $\dataScalar_i$. If a model is non-linear in the
inputs, it means that there is a non-linear function between the
inputs and the response variable. Linear functions are functions that
only involve multiplication and addition, in other words they can be
represented through *linear algebra*. Linear regression involves
assuming that a function takes the form}
$$
\mappingFunction(\inputVector) = \mappingVector^\top \inputVector
$$
\notes{where $\mappingVector$ are our regression weights. A very easy way to make the linear regression non-linear is to introduce non-linear functions. When we are introducing non-linear regression these functions are known as *basis functions*.}

\include{_ml/includes/basis-functions.md}
\include{_ml/includes/basis-function-models.md}

\subsection{Reading}

* Section 1.4 of @Rogers:book11.
* Chapter 1, pg 1-6 of @Bishop:book06.
* Chapter 3, Section 3.1 of @Bishop:book06 up to pg 143.

\subsection{Lecture on Basis Functions from GPRS Uganda}

\includeyoutube{PoNbOnUnOao}

\subsection{Use of QR Decomposition for Numerical Stability}

\notes{In the last session we showed how rather than computing $\inputMatrix^\top\inputMatrix$ as an intermediate step to our solution, we could compute the solution to the regressiond directly through [QR-decomposition](http://en.wikipedia.org/wiki/QR_decomposition). Now we will consider an example with non linear basis functions where such computation is critical for forming the right answer.}

*TODO* example with polynomials.

\setupcode{import numpy as np}

\code{x = np.random.normal(size=(10, 1))}

\code{Phi = fourier(x, 5)}

\code{(np.dot(Phi.T,Phi))}

\code{Phi*Phi}

\subsection{References}
